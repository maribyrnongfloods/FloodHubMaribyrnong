{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "markdown-title",
   "metadata": {},
   "source": [
    "# Derive Gauge Configuration — ausvic (FloodHubMaribyrnong)\n",
    "\n",
    "This notebook reproduces every value in the `GAUGES` list from primary sources.\n",
    "Run it end-to-end to verify or update the gauge configuration.\n",
    "\n",
    "| Field | Source |\n",
    "|-------|--------|\n",
    "| `gauge_id` | Caravan convention: `ausvic_` + station number (no letters) |\n",
    "| `name` | Victorian Water: Hydstra `get_ts_traces` → `site_details.name`; Melbourne Water: `/locations` API |\n",
    "| `lat` / `lon` | Victorian Water: Hydstra `get_ts_traces` → `site_details`; Melbourne Water: `/locations` + `/summary` API |\n",
    "| `area_km2` | HydroBASINS Level-12 `UP_AREA` via GEE (Keilor: official VW figure) |\n",
    "| Exclusions | CAMELS AUS v2 overlap check (Zenodo 13350616) — CSV required |\n",
    "\n",
    "**Steps**\n",
    "1. Candidate discovery + CAMELS AUS v2 overlap\n",
    "2. Victorian Water metadata — name/lat/lon from Hydstra `get_ts_traces` site_details\n",
    "3. Melbourne Water metadata — name/lat/lon from `/locations` + `/summary` API\n",
    "4. Catchment areas — `UP_AREA` from HydroBASINS via GEE\n",
    "5. Compile final `GAUGES` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "print('Ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-mount-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-step1",
   "metadata": {},
   "source": [
    "## Step 1 — Candidate Station Discovery and CAMELS AUS v2 Overlap Check\n",
    "\n",
    "**1a — Victorian Water candidates**  \n",
    "Known 230* stations confirmed to carry discharge (141.00 = ML/day).  \n",
    "Names and coordinates are fetched from the Hydstra API in Step 2.\n",
    "\n",
    "**1b — Melbourne Water candidates via `/locations` API**  \n",
    "Call `api.melbournewater.com.au/rainfall-river-level/locations` to get all MW sites.  \n",
    "Filter to those with a `230` prefix (Maribyrnong basin). Use `/summary` to confirm  \n",
    "each site has flow data (`flowLevels.minYear` present) and extract any available  \n",
    "lat/lon from both responses.\n",
    "\n",
    "**1c — CAMELS AUS v2 overlap**  \n",
    "Any candidate already in Caravan via CAMELS AUS v2 (Zenodo 13350616) is excluded  \n",
    "to avoid duplicate gauge IDs across the global dataset.\n",
    "\n",
    "> **CAMELS CSV required.**  \n",
    "> Download `CAMELS_AUS_Attributes&Indices_MasterTable.csv` from  \n",
    "> [Zenodo record 13350616](https://doi.org/10.5281/zenodo.13350616) and place it in  \n",
    "> `MyDrive/Colab Notebooks/`. The cell raises a `FileNotFoundError` if it is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a05e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station    Name                                                Lat           Lon\n",
      "  ----------------------------------------------------------------------------------\n",
      "  230200     MARIBYRNONG RIVER @ KEILOR                   -37.727706    144.836476\n",
      "  230206     JACKSON CREEK @ GISBORNE                     -37.475370    144.572443\n",
      "  230202     JACKSON CREEK @ SUNBURY                      -37.583217    144.742036\n",
      "  230213     TURRITABLE CREEK @ MOUNT MACEDON             -37.418905    144.584810\n",
      "  230227     MAIN CREEK @ KERRIE                          -37.396121    144.660395\n",
      "\n",
      "5 Victorian Water gauges fetched from Hydstra API\n"
     ]
    }
   ],
   "source": [
    "# ── Step 1a / Step 2 combined: Victorian Water metadata (Hydstra API) ─────────\n",
    "# Station IDs are the known 230* gauges confirmed to carry discharge (141.00 ML/day).\n",
    "# get_site_list is not exposed on this public endpoint — name/lat/lon come from\n",
    "# the site_details object embedded in every get_ts_traces response.\n",
    "\n",
    "import json as _json, urllib.parse as _up, urllib.request as _ur, time as _time\n",
    "\n",
    "HYDSTRA_BASE = 'https://data.water.vic.gov.au/cgi/webservice.exe'\n",
    "VW_STATIONS  = ['230200', '230206', '230202', '230213', '230227']\n",
    "\n",
    "vw_meta = {}\n",
    "\n",
    "print(f'  {\"Station\":<10} {\"Name\":<42} {\"Lat\":>12} {\"Lon\":>13}')\n",
    "print('  ' + '-' * 82)\n",
    "\n",
    "for sid in VW_STATIONS:\n",
    "    params = {\n",
    "        'function':   'get_ts_traces',\n",
    "        'version':    '2',\n",
    "        'site_list':  sid,\n",
    "        'datasource': 'PUBLISH',\n",
    "        'varfrom':    '100.00',\n",
    "        'varto':      '141.00',\n",
    "        'start_time': '20240601000000',\n",
    "        'end_time':   '20240601235959',\n",
    "        'interval':   'day',\n",
    "        'multiplier': '1',\n",
    "        'data_type':  'mean',\n",
    "    }\n",
    "    url = HYDSTRA_BASE + '?' + _up.urlencode(params)\n",
    "    with _ur.urlopen(url, timeout=30) as resp:\n",
    "        data = _json.loads(resp.read().decode())\n",
    "\n",
    "    traces = data.get('return', {}).get('traces', [])\n",
    "    if not traces:\n",
    "        raise RuntimeError(f'No trace returned for Hydstra station {sid}')\n",
    "\n",
    "    sd   = traces[0].get('site_details', {})\n",
    "    name = sd.get('name', '').strip()\n",
    "    lat  = float(sd.get('latitude', 0))\n",
    "    lon  = float(sd.get('longitude', 0))\n",
    "\n",
    "    if not name or lat == 0 or lon == 0:\n",
    "        raise ValueError(f'Incomplete site_details for {sid}: {sd}')\n",
    "\n",
    "    vw_meta[sid] = {'name': name, 'lat': lat, 'lon': lon}\n",
    "    print(f'  {sid:<10} {name:<42} {lat:>12.6f} {lon:>13.6f}')\n",
    "    _time.sleep(0.3)\n",
    "\n",
    "print(f'\\n{len(vw_meta)} Victorian Water gauges fetched from Hydstra API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hib8pnzmbou",
   "metadata": {},
   "outputs": [],
   "source": "# ── Step 1b: Discover Melbourne Water candidates via /locations API ────────────\nMELBWATER_BASE = 'https://api.melbournewater.com.au/rainfall-river-level'\n\nMW_HEADERS = {\n    'User-Agent': 'Mozilla/5.0',\n    'Accept':     'application/json',\n    'Origin':     'https://www.melbournewater.com.au',\n    'Referer':    'https://www.melbournewater.com.au/',\n}\n\n# Known agency duplicates — same physical gauge as a Hydstra station, shorter record.\n# These are excluded here so the Hydstra record (longer) is the sole source.\n#   230104A (MW \"Sunbury\") = Hydstra 230202: Jacksons Ck at Sunbury Road.\n#                            MW record from 1996; Hydstra from 1960 → keep Hydstra.\n#   230105A (MW \"Keilor\")  = Hydstra 230200: same crump weir (BOM uses MW ID).\n#                            MW record from 1996; Hydstra from 1907 → keep Hydstra.\nMW_AGENCY_DUPLICATES = {\n    '230104A': 'agency duplicate of Hydstra 230202',\n    '230105A': 'agency duplicate of Hydstra 230200',\n}\n\ndef check_flow_direct(sid):\n    \"\"\"\n    Fall back to a direct flow request when /summary doesn't expose flowLevels.\n    Uses the Oct 2022 Maribyrnong flood window (10–20 Oct 2022) — a period with\n    well-above-average flows across the entire catchment, guaranteeing a non-empty\n    response at any gauge that carries discharge data.\n    Returns (has_flow: bool, label: str | None).\n    \"\"\"\n    test_url = (f'{MELBWATER_BASE}/{sid}/river-flow/daily/range'\n                f'?fromDate=2022-10-10&toDate=2022-10-20')\n    req = urllib.request.Request(test_url, headers=MW_HEADERS)\n    try:\n        with urllib.request.urlopen(req, timeout=15) as resp:\n            records = json.loads(resp.read().decode())\n        if isinstance(records, list) and records:\n            return True, '(Oct 2022 flood)'\n        if isinstance(records, dict):\n            items = records.get('data', records.get('records', []))\n            if items:\n                return True, '(Oct 2022 flood)'\n    except Exception:\n        pass\n    return False, None\n\n# 1. Get the full locations list\nreq = urllib.request.Request(f'{MELBWATER_BASE}/locations', headers=MW_HEADERS)\nwith urllib.request.urlopen(req, timeout=30) as resp:\n    all_locations = json.loads(resp.read().decode()).get(\"siteLocations\", [])\n\nprint(f'Melbourne Water /locations returned {len(all_locations)} total sites')\n\nmaribyrnong_sites = [\n    loc for loc in all_locations\n    if str(loc.get('siteId', '')).startswith('230')\n]\nprint(f'  {len(maribyrnong_sites)} sites with prefix 230')\nprint(f'\\nSample location object fields: {sorted(maribyrnong_sites[0].keys()) if maribyrnong_sites else \"none\"}')\nprint()\n\n# 2. Process each site — filter out non-streamflow gauges, check for flow data\nmw_candidates = {}\n\nprint(f'  {\"Site ID\":<12} {\"Name\":<40} {\"Status\":<30} {\"Min year\":>10} {\"Lat\":>10} {\"Lon\":>11}')\nprint('  ' + '-' * 118)\n\nfor loc in maribyrnong_sites:\n    sid  = str(loc.get('siteId', '')).strip()\n    name = (loc.get('siteName') or loc.get('name') or loc.get('description') or sid).strip()\n\n    # Filter 1: reservoirs — not a streamflow gauge\n    if loc.get('reservoirRecording'):\n        print(f'  {sid:<12} {name:<40} SKIP — reservoir')\n        continue\n\n    # Filter 2: agency duplicates — same physical gauge as a Hydstra station\n    if sid in MW_AGENCY_DUPLICATES:\n        print(f'  {sid:<12} {name:<40} SKIP — {MW_AGENCY_DUPLICATES[sid]}')\n        continue\n\n    # Call /summary for flow info and coordinates\n    summary_url = f'{MELBWATER_BASE}/{sid}/summary'\n    req = urllib.request.Request(summary_url, headers=MW_HEADERS)\n    try:\n        with urllib.request.urlopen(req, timeout=15) as resp:\n            summary = json.loads(resp.read().decode())\n        flow     = summary.get('flowLevels', {})\n        min_yr   = flow.get('minYear')\n        has_flow = min_yr is not None\n        lat = (summary.get('latitude') or summary.get('lat') or\n               loc.get('latitude') or loc.get('lat'))\n        lon = (summary.get('longitude') or summary.get('lon') or\n               loc.get('longitude') or loc.get('lng') or loc.get('lon'))\n    except Exception:\n        has_flow = False\n        min_yr   = None\n        lat = lon = None\n\n    # Filter 3: very short records (started 2025 or later — insufficient for Caravan)\n    if min_yr is not None and int(min_yr) >= 2025:\n        print(f'  {sid:<12} {name:<40} SKIP — record from {min_yr} only')\n        continue\n\n    # Stage b: direct flood-date check for gauges /summary misses\n    # (e.g. 230102A, 230237A have flow but flowLevels not exposed in /summary)\n    if not has_flow:\n        has_flow, min_yr = check_flow_direct(sid)\n\n    mw_candidates[sid] = {\n        'name': name, 'has_flow': has_flow, 'min_year': min_yr,\n        'lat': float(lat) if lat is not None else None,\n        'lon': float(lon) if lon is not None else None,\n    }\n    status = 'YES' if has_flow else 'no flow'\n    lat_s  = f'{float(lat):.4f}' if lat is not None else 'N/A'\n    lon_s  = f'{float(lon):.4f}' if lon is not None else 'N/A'\n    print(f'  {sid:<12} {name:<40} {status:<30} {str(min_yr or \"\"):>10} {lat_s:>10} {lon_s:>11}')\n    time.sleep(0.3)\n\nmw_with_flow = {sid: v for sid, v in mw_candidates.items() if v['has_flow']}\nprint(f'\\n{len(mw_with_flow)} Melbourne Water sites with flow records')"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-camels-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates (VW + MW, with discharge): 14\n",
      "  230100A      Darraweit\n",
      "  230103A      Rosslynne Reservoir\n",
      "  230104A      Sunbury\n",
      "  230105A      Keilor\n",
      "  230106A      Maribyrnong\n",
      "  230107A      Konagaderra\n",
      "  230200       MARIBYRNONG RIVER @ KEILOR\n",
      "  230202       JACKSON CREEK @ SUNBURY\n",
      "  230206       JACKSON CREEK @ GISBORNE\n",
      "  230211A      Clarkefield\n",
      "  230213       TURRITABLE CREEK @ MOUNT MACEDON\n",
      "  230227       MAIN CREEK @ KERRIE\n",
      "  230232A      Deep Ck at Bolinda\n",
      "  230233A      Jacksons Ck at Gisborne WWTP\n",
      "\n",
      "CAMELS AUS v2 loaded — 561 stations\n",
      "\n",
      "  Station      Name                                          Status\n",
      "  ----------------------------------------------------------------------\n",
      "  230100A      Darraweit                                     OK\n",
      "  230103A      Rosslynne Reservoir                           OK\n",
      "  230104A      Sunbury                                       OK\n",
      "  230105A      Keilor                                        OK\n",
      "  230106A      Maribyrnong                                   OK\n",
      "  230107A      Konagaderra                                   OK\n",
      "  230200       MARIBYRNONG RIVER @ KEILOR                    OK\n",
      "  230202       JACKSON CREEK @ SUNBURY                       OK\n",
      "  230206       JACKSON CREEK @ GISBORNE                      OK\n",
      "  230211A      Clarkefield                                   OK\n",
      "  230213       TURRITABLE CREEK @ MOUNT MACEDON              OK\n",
      "  230227       MAIN CREEK @ KERRIE                           OK\n",
      "  230232A      Deep Ck at Bolinda                            OK\n",
      "  230233A      Jacksons Ck at Gisborne WWTP                  OK\n",
      "\n",
      "Result: 14 included, 0 excluded: []\n"
     ]
    }
   ],
   "source": [
    "# ── Step 1c: Combine all candidates then CAMELS AUS v2 overlap check ──────────\n",
    "import pandas as pd\n",
    "\n",
    "ALL_CANDIDATES = {\n",
    "    **{sid: v['name'] for sid, v in vw_meta.items()},\n",
    "    **{sid: v['name'] for sid, v in mw_with_flow.items()},\n",
    "}\n",
    "print(f'Total candidates (VW + MW, with discharge): {len(ALL_CANDIDATES)}')\n",
    "for sid, name in sorted(ALL_CANDIDATES.items()):\n",
    "    print(f'  {sid:<12} {name}')\n",
    "\n",
    "# CAMELS AUS v2 overlap check — CSV required (download from Zenodo record 13350616)\n",
    "CAMELS_CSV = Path('/content/drive/MyDrive/Colab Notebooks/CAMELS_AUS_Attributes&Indices_MasterTable.csv')\n",
    "\n",
    "if not CAMELS_CSV.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f'CAMELS CSV not found at {CAMELS_CSV}\\n'\n",
    "        'Download from https://doi.org/10.5281/zenodo.13350616 and place in '\n",
    "        'MyDrive/Colab Notebooks/'\n",
    "    )\n",
    "\n",
    "camels     = pd.read_csv(CAMELS_CSV, dtype=str)\n",
    "camels_ids = set(camels['station_id'].str.strip())\n",
    "print(f'\\nCAMELS AUS v2 loaded — {len(camels_ids)} stations\\n')\n",
    "\n",
    "EXCLUDED = set()\n",
    "print(f'  {\"Station\":<12} {\"Name\":<45} Status')\n",
    "print('  ' + '-' * 70)\n",
    "for sid, name in sorted(ALL_CANDIDATES.items()):\n",
    "    camels_sid = sid.rstrip('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    if camels_sid in camels_ids:\n",
    "        EXCLUDED.add(sid)\n",
    "        status = 'DUPLICATE -> EXCLUDED'\n",
    "    else:\n",
    "        status = 'OK'\n",
    "    print(f'  {sid:<12} {name:<45} {status}')\n",
    "\n",
    "INCLUDED = {sid: name for sid, name in ALL_CANDIDATES.items() if sid not in EXCLUDED}\n",
    "print(f'\\nResult: {len(INCLUDED)} included, {len(EXCLUDED)} excluded: {sorted(EXCLUDED)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-step3",
   "metadata": {},
   "source": [
    "## Step 3 — Melbourne Water Gauge Metadata\n",
    "\n",
    "Coordinates and names are extracted from the `/locations` and `/summary` API  \n",
    "responses fetched in Step 1b. The \"Sample location object fields\" output in Step 1b  \n",
    "shows every field the API exposes — if coordinates are not found, Step 3 will raise  \n",
    "a `ValueError` identifying the affected gauges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-melbwater-verify",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Site ID      Name                                       Min year          Lat           Lon Coord source\n",
      "  ------------------------------------------------------------------------------------------------------\n",
      "  230100A      Darraweit                                      1996   -37.410313    144.902285  API\n",
      "  230103A      Rosslynne Reservoir                            1996   -37.473800    144.569000  API\n",
      "  230104A      Sunbury                                        1996   -37.583300    144.742000  API\n",
      "  230105A      Keilor                                         1996   -37.727500    144.836000  API\n",
      "  230106A      Maribyrnong                                    1996   -37.765900    144.895000  API\n",
      "  230107A      Konagaderra                                    1996   -37.528500    144.856000  API\n",
      "  230211A      Clarkefield                                    2008   -37.466200    144.744000  API\n",
      "  230232A      Deep Ck at Bolinda                             2025   -37.426829    144.817363  API\n",
      "  230233A      Jacksons Ck at Gisborne WWTP                   2025   -37.487981    144.616081  API\n",
      "\n",
      "9 Melbourne Water gauges ready\n"
     ]
    }
   ],
   "source": [
    "# ── Step 3: Melbourne Water metadata from /locations + /summary ───────────────\n",
    "# Coordinates are extracted in Step 1b from the /summary and /locations API\n",
    "# responses. No hardcoded fallback — if the API doesn't return coords for a\n",
    "# gauge in our included set the cell will raise an error.\n",
    "\n",
    "loc_lookup = {str(loc.get('siteId', '')).strip(): loc for loc in all_locations}\n",
    "\n",
    "print(f'  {\"Site ID\":<12} {\"Name\":<40} {\"Min year\":>10} {\"Lat\":>12} {\"Lon\":>13} {\"Coord source\"}')\n",
    "print('  ' + '-' * 102)\n",
    "\n",
    "mw_meta = {}\n",
    "missing_coords = []\n",
    "\n",
    "for sid, v in sorted(mw_with_flow.items()):\n",
    "    if sid in EXCLUDED:\n",
    "        continue\n",
    "\n",
    "    name = v['name']\n",
    "    lat  = v.get('lat')\n",
    "    lon  = v.get('lon')\n",
    "    coord_src = 'API' if lat is not None else 'MISSING'\n",
    "\n",
    "    if lat is None or lon is None:\n",
    "        missing_coords.append(sid)\n",
    "\n",
    "    mw_meta[sid] = {'name': name, 'lat': lat, 'lon': lon, 'min_year': v['min_year']}\n",
    "    lat_s = f'{lat:.6f}' if lat is not None else 'MISSING'\n",
    "    lon_s = f'{lon:.6f}' if lon is not None else 'MISSING'\n",
    "    print(f'  {sid:<12} {name:<40} {str(v[\"min_year\"]):>10} {lat_s:>12} {lon_s:>13}  {coord_src}')\n",
    "\n",
    "print(f'\\n{len(mw_meta)} Melbourne Water gauges ready')\n",
    "\n",
    "if missing_coords:\n",
    "    raise ValueError(\n",
    "        f'Coordinates missing for {missing_coords}.\\n'\n",
    "        'The Melbourne Water API did not return lat/lon for these gauges.\\n'\n",
    "        'Check the \"Sample location object fields\" output in Step 1b to find\\n'\n",
    "        'the correct field names, then update the lat/lon extraction in that cell.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-step4",
   "metadata": {},
   "source": [
    "## Step 4 â€” Catchment Areas from HydroBASINS (GEE)\n",
    "\n",
    "For each gauge, the `UP_AREA` field from the HydroBASINS Level-12 outlet cell\n",
    "gives the upstream drainage area in kmÂ². This is used as `area_km2` in the\n",
    "GAUGES config for all stations except Keilor (230200), which uses the official\n",
    "Victorian Water figure of **1305.4 kmÂ²** (based on 586 gaugings 1908â€“2025).\n",
    "\n",
    "This cell makes one GEE point query per gauge â€” no BFS tracing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gee-auth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='floodhubmaribyrnong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-up-area",
   "metadata": {},
   "outputs": [],
   "source": "# ── Step 4: HydroBASINS UP_AREA lookup for all included gauges ────────────────\n# GAUGE_META is derived from the filtered API results — no hardcoded station list.\n#   VW stations: all of vw_meta (all 5 passed filtering in Step 1a/2)\n#   MW stations: all of mw_with_flow (filtering in Step 1b removed reservoirs,\n#                agency duplicates, and 2025-only records)\n#\n# gauge_id format: 'ausvic_' + numeric part of station ID (Caravan convention)\n\nKEILOR_OFFICIAL_AREA_KM2 = 1305.4   # Victorian Water official figure (586 gaugings 1908–2025)\n\nGAUGE_META = (\n    [(sid, 'ausvic_' + sid, 'hydstra')\n     for sid in vw_meta] +\n    [(sid, 'ausvic_' + sid.rstrip('ABCDEFGHIJKLMNOPQRSTUVWXYZ'), 'melbwater')\n     for sid in mw_with_flow]\n)\n\nprint(f'{len(GAUGE_META)} gauges in GAUGE_META ({len(vw_meta)} VW + {len(mw_with_flow)} MW)')\nfor sid, gid, src in GAUGE_META:\n    print(f'  {sid:<12} → {gid}  ({src})')\n\n# Build coord list from API-derived metadata\nALL_GAUGE_COORDS = (\n    [(sid, gid, vw_meta[sid]['lat'], vw_meta[sid]['lon'])\n     for sid, gid, src in GAUGE_META if src == 'hydstra' and sid in vw_meta] +\n    [(sid, gid, mw_meta[sid]['lat'], mw_meta[sid]['lon'])\n     for sid, gid, src in GAUGE_META if src == 'melbwater' and sid in mw_meta]\n)\n\nbasins   = ee.FeatureCollection('WWF/HydroSHEDS/v1/Basins/hybas_12')\nup_areas = {}\n\nprint(f'\\n  {\"Station\":<10} {\"Gauge ID\":<20} {\"HydroBASINS UP_AREA\":>20} {\"area_km2 used\":>14}')\nprint('  ' + '-' * 70)\n\nfor sid, gid, lat, lon in ALL_GAUGE_COORDS:\n    point   = ee.Geometry.Point([lon, lat])\n    outlet  = basins.filterBounds(point).first().getInfo()\n    up_area = outlet['properties']['UP_AREA']\n\n    if sid == '230200':\n        area_used = KEILOR_OFFICIAL_AREA_KM2\n        note      = f' <- official VW (HydroBASINS: {up_area:.1f})'\n    else:\n        area_used = round(up_area, 1)\n        note      = ''\n\n    up_areas[gid] = area_used\n    print(f'  {sid:<10} {gid:<20} {up_area:>20.1f} {area_used:>14.1f}{note}')\n\nprint(f'\\nAreas fetched for {len(up_areas)} gauges.')"
  },
  {
   "cell_type": "markdown",
   "id": "markdown-step5",
   "metadata": {},
   "source": [
    "## Step 5 â€” Compile Final GAUGES List\n",
    "\n",
    "Combines all sources into the final `GAUGES` configuration.\n",
    "The output matches `gauges_config.py` in the project repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compile",
   "metadata": {},
   "outputs": [],
   "source": "# ── Compile GAUGES from all derived sources ────────────────────────────────────\n# GAUGE_META is defined in Step 4. Name/lat/lon come from vw_meta (Step 2) and\n# mw_meta (Step 3). area_km2 comes from up_areas (Step 4).\n\n# Canonical name overrides — MW API returns generic names that don't match the\n# gauging station's actual river (corrected from Jacobs/MW Oct 2022 flood analysis):\n#   230100A: API returns Maribyrnong River name — gauge is on Deep Creek\n#   230211A: API returns Maribyrnong River name — gauge is on Bolinda Creek\nNAME_OVERRIDES = {\n    '230100A': 'Deep Creek at Darraweit Guim',\n    '230211A': 'Bolinda Creek at Clarkefield',\n}\n\nGAUGES = []\nfor sid, gid, source in GAUGE_META:\n    meta = vw_meta.get(sid, {}) if source == 'hydstra' else mw_meta.get(sid, {})\n\n    api_name = meta.get('name', f'Station {sid}')\n    name     = NAME_OVERRIDES.get(sid, api_name)\n    if name != api_name:\n        print(f'  Name override for {sid}: {api_name!r} -> {name!r}')\n\n    GAUGES.append({\n        'gauge_id':  gid,\n        'name':      name,\n        'lat':       meta.get('lat'),\n        'lon':       meta.get('lon'),\n        'area_km2':  up_areas.get(gid),\n    })\n\nORDER = [\n    'ausvic_230100', 'ausvic_230102', 'ausvic_230211', 'ausvic_230107',\n    'ausvic_230237', 'ausvic_230106',\n    'ausvic_230200',\n    'ausvic_230206', 'ausvic_230202', 'ausvic_230213', 'ausvic_230227',\n]\nGAUGES.sort(key=lambda g: ORDER.index(g['gauge_id']) if g['gauge_id'] in ORDER else 99)\n\nprint(f'{len(GAUGES)} gauges compiled\\n')\nprint(f'  {\"gauge_id\":<20} {\"name\":<42} {\"lat\":>12} {\"lon\":>13} {\"area_km2\":>10}')\nprint('  ' + '-' * 103)\nfor g in GAUGES:\n    print(f\"  {g['gauge_id']:<20} {g['name']:<42} {g['lat']:>12.6f} {g['lon']:>13.6f} {g['area_km2']:>10.1f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-print-gauges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Print as Python dict literal (copy into gauges_config.py if updated) â”€â”€â”€â”€â”€â”€\n",
    "print('GAUGES = [')\n",
    "for g in GAUGES:\n",
    "    print(f\"    {{'gauge_id': {repr(g['gauge_id']):<22} 'name': {repr(g['name']):<46} \"\n",
    "          f\"'lat': {g['lat']:<16} 'lon': {g['lon']:<16} 'area_km2': {g['area_km2']}}},\")\n",
    "print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-validate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "errors = []\n",
    "\n",
    "for g in GAUGES:\n",
    "    gid = g['gauge_id']\n",
    "    if len(gid.split('_')) != 2:\n",
    "        errors.append(f\"{gid}: gauge_id must have exactly 2 parts\")\n",
    "    if not gid.startswith('ausvic_'):\n",
    "        errors.append(f\"{gid}: must start with 'ausvic_'\")\n",
    "    if g['lat'] is None or g['lon'] is None:\n",
    "        errors.append(f\"{gid}: missing lat/lon\")\n",
    "    if g['area_km2'] is None or g['area_km2'] <= 0:\n",
    "        errors.append(f\"{gid}: invalid area_km2\")\n",
    "    if not (-90 <= g['lat'] <= 90 and 100 <= g['lon'] <= 160):\n",
    "        errors.append(f\"{gid}: coordinates outside Victoria bounds\")\n",
    "\n",
    "if errors:\n",
    "    print('ERRORS:')\n",
    "    for e in errors:\n",
    "        print(f'  {e}')\n",
    "else:\n",
    "    print(f'All {len(GAUGES)} gauges passed validation.')\n",
    "    print('  - gauge_id format: OK (ausvic_XXXXXX, 2 parts)')\n",
    "    print('  - lat/lon present: OK')\n",
    "    print('  - area_km2 > 0:    OK')\n",
    "    print('  - coords in VIC:   OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hifwrd2sy2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Save GAUGES to Google Drive as JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Downstream notebooks (0b-fetch_catchments, etc.) load from this file\n",
    "# instead of hardcoding the gauge list â€” single source of truth.\n",
    "\n",
    "GAUGES_JSON = Path('/content/drive/MyDrive/caravan_maribyrnong_gee/gauges_ausvic.json')\n",
    "GAUGES_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(GAUGES_JSON, 'w') as f:\n",
    "    json.dump(GAUGES, f, indent=2)\n",
    "\n",
    "print(f'GAUGES saved: {GAUGES_JSON}')\n",
    "print(f'  {len(GAUGES)} gauges, fields: {list(GAUGES[0].keys())}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "derive_gauge_config_ausvic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}