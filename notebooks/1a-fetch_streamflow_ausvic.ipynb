{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-header",
   "metadata": {},
   "source": [
    "# 1a — Fetch streamflow for ausvic gauges\n",
    "\n",
    "Fetches daily mean flow (ML/day) from both data providers for all 12 Maribyrnong gauges,\n",
    "converts to mm/day, and writes per-gauge CSVs ready for the Part 2 postprocessing notebook.\n",
    "\n",
    "**Run this notebook locally** (no Google Earth Engine required).\n",
    "\n",
    "## What it does\n",
    "\n",
    "1. Loads gauge config from `caravan_maribyrnong_gee/gauges_ausvic.json` (same file as 0a / 0b)\n",
    "2. Fetches 7 Melbourne Water gauges from `api.melbournewater.com.au`\n",
    "3. Fetches 5 Victorian Water gauges from `data.water.vic.gov.au` (Hydstra API)\n",
    "4. Converts ML/day → mm/day using `area_km2` from the JSON\n",
    "5. Filters negatives, bad quality flags, deduplicates, sorts chronologically\n",
    "6. Saves one CSV per gauge to `caravan_maribyrnong/timeseries/csv/ausvic/{gauge_id}.csv`\n",
    "\n",
    "## Output CSV format\n",
    "\n",
    "Each file has two columns: `date` (YYYY-MM-DD) and `streamflow` (mm/day, empty string for missing).\n",
    "The date index is **daily** with no gaps — required by the Part 2 validation check.\n",
    "\n",
    "## Station ID mapping\n",
    "\n",
    "| gauge_id | Station ID | API |\n",
    "|----------|-----------|-----|\n",
    "| ausvic_230119 | 230119A | Melbourne Water |\n",
    "| ausvic_230100 | 230100A | Melbourne Water |\n",
    "| ausvic_230102 | 230102A | Melbourne Water |\n",
    "| ausvic_230211 | 230211A | Melbourne Water |\n",
    "| ausvic_230107 | 230107A | Melbourne Water |\n",
    "| ausvic_230237 | 230237A | Melbourne Water |\n",
    "| ausvic_230106 | 230106A | Melbourne Water |\n",
    "| ausvic_230200 | 230200  | Victorian Water |\n",
    "| ausvic_230206 | 230206  | Victorian Water |\n",
    "| ausvic_230202 | 230202  | Victorian Water |\n",
    "| ausvic_230213 | 230213  | Victorian Water |\n",
    "| ausvic_230227 | 230227  | Victorian Water |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root : C:\\Users\\leela\\FloodHubMaribyrnong\n",
      "Loaded 12 gauges from C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong_gee\\gauges_ausvic.json\n",
      "Output dir   : C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\n",
      "fetch_start overrides: {'ausvic_230202': '1960-01-01'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ── Resolve project root ───────────────────────────────────────────────────\n",
    "# Works whether the kernel CWD is the project root OR the notebooks/ folder.\n",
    "_cwd = Path('.').resolve()\n",
    "PROJECT_ROOT = _cwd.parent if _cwd.name == 'notebooks' else _cwd\n",
    "\n",
    "# ── Paths ──────────────────────────────────────────────────────────────────\n",
    "GAUGES_JSON = PROJECT_ROOT / 'caravan_maribyrnong_gee' / 'gauges_ausvic.json'\n",
    "OUT_DIR     = PROJECT_ROOT / 'caravan_maribyrnong' / 'timeseries' / 'csv' / 'ausvic'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── Load gauge config ─────────────────────────────────────────────────────\n",
    "with open(GAUGES_JSON) as f:\n",
    "    GAUGES = json.load(f)\n",
    "\n",
    "# Station ID mapping: gauge_id → (raw station ID, API source)\n",
    "# Melbourne Water station IDs have a trailing letter (always 'A' in this network).\n",
    "STATION_IDS = {\n",
    "    'ausvic_230119': ('230119A', 'melbwater'),\n",
    "    'ausvic_230100': ('230100A', 'melbwater'),\n",
    "    'ausvic_230102': ('230102A', 'melbwater'),\n",
    "    'ausvic_230211': ('230211A', 'melbwater'),\n",
    "    'ausvic_230107': ('230107A', 'melbwater'),\n",
    "    'ausvic_230237': ('230237A', 'melbwater'),\n",
    "    'ausvic_230106': ('230106A', 'melbwater'),\n",
    "    'ausvic_230200': ('230200',  'hydstra'),\n",
    "    'ausvic_230206': ('230206',  'hydstra'),\n",
    "    'ausvic_230202': ('230202',  'hydstra'),\n",
    "    'ausvic_230213': ('230213',  'hydstra'),\n",
    "    'ausvic_230227': ('230227',  'hydstra'),\n",
    "}\n",
    "\n",
    "# Earliest date to keep per gauge (inclusive). Rows before this date are dropped.\n",
    "# Rationale for 230202: Hydstra returns data from 1908 but values 1908-1959 are\n",
    "# ~0.25 ML/day artefacts (level-derived, no proper rating curve). The gauge was\n",
    "# properly operational from 1960. Including pre-1960 data would mislead flood\n",
    "# models (ERA5 forcing exists 1950-1960 but streamflow is near-zero artefact).\n",
    "FETCH_START = {\n",
    "    'ausvic_230202': '1960-01-01',\n",
    "}\n",
    "\n",
    "print(f'Project root : {PROJECT_ROOT}')\n",
    "print(f'Loaded {len(GAUGES)} gauges from {GAUGES_JSON}')\n",
    "print(f'Output dir   : {OUT_DIR}')\n",
    "print(f'fetch_start overrides: {FETCH_START}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-mw-md",
   "metadata": {},
   "source": [
    "## Melbourne Water API\n",
    "\n",
    "Endpoint: `https://api.melbournewater.com.au/rainfall-river-level/{station_id}/river-flow/daily/range`  \n",
    "Parameters: `fromDate=YYYY-MM-DD&toDate=YYYY-MM-DD`  \n",
    "Response key: `dailyRiverFlowsData` → list of `{dateTime, meanRiverFlow}`\n",
    "\n",
    "Fetched in yearly chunks (API may impose request limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-mw-fetch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne Water fetch function defined.\n"
     ]
    }
   ],
   "source": [
    "MELBWATER_BASE = 'https://api.melbournewater.com.au/rainfall-river-level'\n",
    "\n",
    "MW_HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0',\n",
    "    'Accept':     'application/json',\n",
    "    'Origin':     'https://www.melbournewater.com.au',\n",
    "    'Referer':    'https://www.melbournewater.com.au/',\n",
    "}\n",
    "\n",
    "def fetch_mw_flow(station_id, start_year=1990):\n",
    "    \"\"\"\n",
    "    Fetch all available daily flow data for a Melbourne Water station.\n",
    "\n",
    "    Returns a list of (iso_date_str, ml_per_day) tuples.\n",
    "    Filters out negative flows.\n",
    "    dateTime field is Melbourne local time 'YYYY-MM-DD HH:MM:SS' — date part only.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    today = date.today()\n",
    "    yr = start_year\n",
    "\n",
    "    while yr <= today.year:\n",
    "        yr_end = min(yr + 4, today.year)  # 5-year chunks\n",
    "        from_dt = f'{yr}-01-01'\n",
    "        to_dt   = f'{yr_end}-12-31' if yr_end < today.year else today.isoformat()\n",
    "\n",
    "        url = (f'{MELBWATER_BASE}/{station_id}/river-flow/daily/range'\n",
    "               f'?fromDate={from_dt}&toDate={to_dt}')\n",
    "        req = urllib.request.Request(url, headers=MW_HEADERS)\n",
    "        try:\n",
    "            with urllib.request.urlopen(req, timeout=30) as resp:\n",
    "                data = json.loads(resp.read().decode())\n",
    "        except Exception as e:\n",
    "            print(f'    [warn] {station_id} {from_dt}–{to_dt}: {e}')\n",
    "            yr = yr_end + 1\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "\n",
    "        for rec in data.get('dailyRiverFlowsData', []):\n",
    "            flow = rec.get('meanRiverFlow')\n",
    "            dt   = rec.get('dateTime', '')\n",
    "            if flow is None or not dt:\n",
    "                continue\n",
    "            if float(flow) < 0:\n",
    "                continue\n",
    "            rows.append((dt[:10], float(flow)))\n",
    "\n",
    "        yr = yr_end + 1\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    return rows\n",
    "\n",
    "print('Melbourne Water fetch function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-vw-md",
   "metadata": {},
   "source": [
    "## Victorian Water / Hydstra API\n",
    "\n",
    "Endpoint: `https://data.water.vic.gov.au/cgi/webservice.exe`  \n",
    "Function: `get_ts_traces`, variable `141.00` (ML/day discharge), datasource `PUBLISH`  \n",
    "Response: `return.traces[0].trace` → list of `{t, v, q}`  \n",
    "Quality flag 255 = bad data — filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-vw-fetch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victorian Water fetch function defined.\n"
     ]
    }
   ],
   "source": [
    "HYDSTRA_BASE = 'https://data.water.vic.gov.au/cgi/webservice.exe'\n",
    "\n",
    "def fetch_vw_flow(station_id):\n",
    "    \"\"\"\n",
    "    Fetch all available daily mean discharge (141.00 = ML/day) for a Victorian Water station.\n",
    "\n",
    "    Returns a list of (iso_date_str, ml_per_day) tuples.\n",
    "    Filters quality flag 255 (bad data) and negative values.\n",
    "    Timestamp field t is YYYYMMDD[HHMMSS] — date part is first 8 chars.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'function':   'get_ts_traces',\n",
    "        'version':    '2',\n",
    "        'site_list':  station_id,\n",
    "        'datasource': 'PUBLISH',\n",
    "        'varfrom':    '100.00',\n",
    "        'varto':      '141.00',\n",
    "        'start_time': '19000101000000',\n",
    "        'end_time':   date.today().strftime('%Y%m%d235959'),\n",
    "        'interval':   'day',\n",
    "        'multiplier': '1',\n",
    "        'data_type':  'mean',\n",
    "    }\n",
    "\n",
    "    url  = f'{HYDSTRA_BASE}?{urllib.parse.urlencode(params)}'\n",
    "    with urllib.request.urlopen(url, timeout=60) as resp:\n",
    "        data = json.loads(resp.read().decode())\n",
    "\n",
    "    traces = data.get('return', {}).get('traces', [])\n",
    "    if not traces:\n",
    "        print(f'  [warn] No traces returned for {station_id}')\n",
    "        return []\n",
    "\n",
    "    rows = []\n",
    "    for pt in traces[0].get('trace', []):\n",
    "        if pt.get('q') == 255 or pt.get('v') in ('', None):\n",
    "            continue\n",
    "        raw = float(pt['v'])\n",
    "        if raw < 0:\n",
    "            continue\n",
    "        ts = str(pt['t'])\n",
    "        if len(ts) < 8:\n",
    "            continue\n",
    "        rows.append((f'{ts[:4]}-{ts[4:6]}-{ts[6:8]}', raw))\n",
    "\n",
    "    return rows\n",
    "\n",
    "print('Victorian Water fetch function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-convert-md",
   "metadata": {},
   "source": [
    "## Build per-gauge daily DataFrames\n",
    "\n",
    "For each gauge:\n",
    "1. Fetch raw ML/day from the appropriate API\n",
    "2. Deduplicate on date (keep first after sort)\n",
    "3. Convert ML/day → mm/day: `flow_mm = flow_ML / area_km2`\n",
    "4. Build a complete daily date index (no gaps) — required by Part 2\n",
    "5. Missing days get empty string (Caravan convention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-fetch-all",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fetching ausvic_230119 (230119A, melbwater) ...   8094 valid days / 10749 total | 24.7% missing | 1996-09-25 – 2026-02-28\n",
      "  Fetching ausvic_230100 (230100A, melbwater) ...   8094 valid days / 10749 total | 24.7% missing | 1996-09-25 – 2026-02-28\n",
      "  Fetching ausvic_230102 (230102A, melbwater) ...   8094 valid days / 10749 total | 24.7% missing | 1996-09-25 – 2026-02-28\n",
      "  Fetching ausvic_230211 (230211A, melbwater) ...   6504 valid days / 6507 total | 0.0% missing | 2008-05-07 – 2026-02-28\n",
      "  Fetching ausvic_230107 (230107A, melbwater) ...   8078 valid days / 10749 total | 24.8% missing | 1996-09-25 – 2026-02-28\n",
      "  Fetching ausvic_230237 (230237A, melbwater) ...   6611 valid days / 6702 total | 1.4% missing | 2007-10-25 – 2026-02-28\n",
      "  Fetching ausvic_230200 (230200, hydstra) ...  36490 valid days / 43126 total | 15.4% missing | 1908-02-02 – 2026-02-27\n",
      "  Fetching ausvic_230106 (230106A, melbwater) ...   8078 valid days / 10749 total | 24.8% missing | 1996-09-25 – 2026-02-28\n",
      "  Fetching ausvic_230206 (230206, hydstra) ...  24035 valid days / 24035 total | 0.0% missing | 1960-05-10 – 2026-02-27\n",
      "  Fetching ausvic_230202 (230202, hydstra) ...  24165 valid days / 24165 total | 0.0% missing | 1960-01-01 – 2026-02-27  [start clipped to 1960-01-01]\n",
      "  Fetching ausvic_230213 (230213, hydstra) ...  18627 valid days / 18627 total | 0.0% missing | 1975-03-01 – 2026-02-27\n",
      "  Fetching ausvic_230227 (230227, hydstra) ...  10629 valid days / 13234 total | 19.7% missing | 1989-12-05 – 2026-02-27\n"
     ]
    }
   ],
   "source": [
    "def build_daily_series(rows_ml, area_km2, fetch_start=None):\n",
    "    \"\"\"\n",
    "    Given a list of (iso_date, ml_per_day) tuples, build a complete daily\n",
    "    pandas Series in mm/day with no date gaps.\n",
    "\n",
    "    fetch_start: optional 'YYYY-MM-DD' string — rows before this date are dropped.\n",
    "    Missing days → NaN (written as empty string to CSV).\n",
    "    Deduplicates: keeps first occurrence after chronological sort.\n",
    "    \"\"\"\n",
    "    if not rows_ml:\n",
    "        return pd.Series(dtype=float, name='streamflow')\n",
    "\n",
    "    df = (pd.DataFrame(rows_ml, columns=['date', 'flow_ml'])\n",
    "            .assign(date=lambda d: pd.to_datetime(d['date']))\n",
    "            .sort_values('date')\n",
    "            .drop_duplicates('date', keep='first')\n",
    "            .set_index('date'))\n",
    "\n",
    "    # Apply fetch_start cutoff if specified\n",
    "    if fetch_start:\n",
    "        df = df.loc[fetch_start:]\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.Series(dtype=float, name='streamflow')\n",
    "\n",
    "    # Convert ML/day → mm/day  (ML/day ÷ area_km2 = mm/day)\n",
    "    df['streamflow'] = df['flow_ml'] / area_km2\n",
    "\n",
    "    # Reindex to a gapless daily spine\n",
    "    full_idx = pd.date_range(df.index.min(), df.index.max(), freq='D')\n",
    "    series = df['streamflow'].reindex(full_idx)\n",
    "    series.index.name = 'date'\n",
    "    series.name = 'streamflow'\n",
    "    return series\n",
    "\n",
    "\n",
    "results = {}  # gauge_id → pd.Series\n",
    "\n",
    "for g in GAUGES:\n",
    "    gid      = g['gauge_id']\n",
    "    area     = g['area_km2']\n",
    "    sid, src = STATION_IDS[gid]\n",
    "    start    = FETCH_START.get(gid)\n",
    "\n",
    "    print(f'  Fetching {gid} ({sid}, {src}) ...', end=' ', flush=True)\n",
    "\n",
    "    try:\n",
    "        if src == 'melbwater':\n",
    "            rows = fetch_mw_flow(sid, start_year=1990)\n",
    "        else:\n",
    "            rows = fetch_vw_flow(sid)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: {e}')\n",
    "        results[gid] = pd.Series(dtype=float, name='streamflow')\n",
    "        continue\n",
    "\n",
    "    series = build_daily_series(rows, area, fetch_start=start)\n",
    "    results[gid] = series\n",
    "\n",
    "    n_valid   = series.notna().sum()\n",
    "    n_total   = len(series)\n",
    "    pct_miss  = 100 * series.isna().sum() / n_total if n_total > 0 else 0\n",
    "    date_rng  = f'{series.index.min().date()} – {series.index.max().date()}' if n_total > 0 else 'no data'\n",
    "    flag      = f'  [start clipped to {start}]' if start else ''\n",
    "    print(f'{n_valid:>6} valid days / {n_total} total | {pct_miss:.1f}% missing | {date_rng}{flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-save-md",
   "metadata": {},
   "source": [
    "## Save CSVs\n",
    "\n",
    "Each CSV: `date` (index), `streamflow` (mm/day or empty string for missing).  \n",
    "The Part 2 notebook reads these with `pd.to_numeric(..., errors='coerce')` which converts\n",
    "empty strings back to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230119.csv  (10749 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230100.csv  (10749 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230102.csv  (10749 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230211.csv  (6507 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230107.csv  (10749 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230237.csv  (6702 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230200.csv  (43126 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230106.csv  (10749 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230206.csv  (24035 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230202.csv  (24165 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230213.csv  (18627 rows)\n",
      "  Saved C:\\Users\\leela\\FloodHubMaribyrnong\\caravan_maribyrnong\\timeseries\\csv\\ausvic\\ausvic_230227.csv  (13234 rows)\n",
      "\n",
      "12 / 12 gauges saved.\n"
     ]
    }
   ],
   "source": [
    "saved = []\n",
    "\n",
    "for gid, series in results.items():\n",
    "    if len(series) == 0:\n",
    "        print(f'  [skip] {gid} — no data fetched')\n",
    "        continue\n",
    "\n",
    "    # Convert NaN → empty string (Caravan missing-value convention)\n",
    "    out = series.round(4).to_frame()\n",
    "    out['streamflow'] = out['streamflow'].map(\n",
    "        lambda x: '' if pd.isna(x) else f'{x:.4f}'\n",
    "    )\n",
    "\n",
    "    out_path = OUT_DIR / f'{gid}.csv'\n",
    "    out.to_csv(out_path)\n",
    "    saved.append(gid)\n",
    "    print(f'  Saved {out_path}  ({len(out)} rows)')\n",
    "\n",
    "print(f'\\n{len(saved)} / {len(GAUGES)} gauges saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary-md",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauge_id                station  source        area km2  valid days          from           to   % missing\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "ausvic_230119           230119A  melbwater        226.1        8094    1996-09-25   2026-02-28       24.7%\n",
      "ausvic_230100           230100A  melbwater        481.5        8094    1996-09-25   2026-02-28       24.7%\n",
      "ausvic_230102           230102A  melbwater        857.5        8094    1996-09-25   2026-02-28       24.7%\n",
      "ausvic_230211           230211A  melbwater         94.9        6504    2008-05-07   2026-02-28        0.0%\n",
      "ausvic_230107           230107A  melbwater        618.0        8078    1996-09-25   2026-02-28       24.8%\n",
      "ausvic_230237           230237A  melbwater       1278.1        6611    2007-10-25   2026-02-28        1.4%\n",
      "ausvic_230200            230200  hydstra         1305.4       36490    1908-02-02   2026-02-27       15.4%\n",
      "ausvic_230106           230106A  melbwater       1385.0        8078    1996-09-25   2026-02-28       24.8%\n",
      "ausvic_230206            230206  hydstra           92.3       24035    1960-05-10   2026-02-27        0.0%\n",
      "ausvic_230202            230202  hydstra          351.0       24165    1960-01-01   2026-02-27        0.0%\n",
      "ausvic_230213            230213  hydstra          109.8       18627    1975-03-01   2026-02-27        0.0%\n",
      "ausvic_230227            230227  hydstra          177.8       10629    1989-12-05   2026-02-27       19.7%\n",
      "\n",
      "NOTE: Chifley Drive (230106A) is tidal — expect many missing days.\n",
      "NOTE: Keilor (230200) should have records from 1907.\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"gauge_id\":<22} {\"station\":>8}  {\"source\":<12} {\"area km2\":>9}  {\"valid days\":>10}  {\"from\":>12} {\"to\":>12}  {\"% missing\":>10}')\n",
    "print('-' * 110)\n",
    "\n",
    "for g in GAUGES:\n",
    "    gid      = g['gauge_id']\n",
    "    area     = g['area_km2']\n",
    "    sid, src = STATION_IDS[gid]\n",
    "    series   = results.get(gid, pd.Series(dtype=float))\n",
    "\n",
    "    if len(series) == 0:\n",
    "        print(f'{gid:<22} {sid:>8}  {src:<12} {area:>9.1f}  {\"NO DATA\":>10}')\n",
    "        continue\n",
    "\n",
    "    n_valid  = int(series.notna().sum())\n",
    "    n_total  = len(series)\n",
    "    pct_miss = 100 * series.isna().sum() / n_total\n",
    "    d_from   = str(series.index.min().date())\n",
    "    d_to     = str(series.index.max().date())\n",
    "\n",
    "    print(f'{gid:<22} {sid:>8}  {src:<12} {area:>9.1f}  {n_valid:>10}  {d_from:>12} {d_to:>12}  {pct_miss:>9.1f}%')\n",
    "\n",
    "print()\n",
    "print('NOTE: Chifley Drive (230106A) is tidal — expect many missing days.')\n",
    "print('NOTE: Keilor (230200) should have records from 1907.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-next-md",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "Run **`2-Caravan_part2_local_postprocessing_ausvic.ipynb`** to merge these streamflow CSVs\n",
    "with the ERA5-Land forcing data from the `caravan_maribyrnong_gee/batch*.csv` files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
